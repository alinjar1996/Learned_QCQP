{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch_optimizer as optim_custom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.bernstein_torch import bernstein_coeff_order10_new\n",
    "# import scipy.io as sio\n",
    "\n",
    "# from models.mlp_qp_vis_aware_2 import MLP, vis_aware_track_net, PointNet\n",
    "# import pol_matrix_comp\n",
    "# from tqdm import trange\n",
    "\n",
    "from models.learned_optim_qcqp_3 import PointNet, CustomGRULayer, GRU_Hidden_State, MLP_Init, Learned_QCQP\n",
    "from scipy.io import loadmat\n",
    "import pol_matrix_comp\n",
    "\n",
    "import bernstein_coeff_order10_arbitinterval\n",
    "# torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_fin = 10.0\n",
    "num = 100\n",
    "tot_time = np.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "\n",
    "\n",
    "P_np, Pdot_np, Pddot_np = pol_matrix_comp.pol_matrix_comp(tot_time_copy)\n",
    "#\n",
    "# P_np, Pdot_np, Pddot_np = bernstein_coeff_order10_arbitinterval.bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "\n",
    "\n",
    "nvar = np.shape(P_np)[1]\n",
    "\n",
    "P = torch.from_numpy(P_np).float()\n",
    "Pdot = torch.from_numpy(Pdot_np).float()\n",
    "Pddot = torch.from_numpy(Pddot_np).float()\n",
    "\n",
    "P_diag = torch.block_diag(P, P)\n",
    "Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_obs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = loadmat('./dataset/goal_reaching_dataset_4.mat')\n",
    "\n",
    "init_state_ego = data['init_state_ego']\n",
    "goal_des = data['goal_des']\n",
    "closest_obs = data['closest_obs']\n",
    "v_obs = data['v_obs']\n",
    "y_lane_bound = data['y_lane_bound']\n",
    "y_lb = y_lane_bound[:, 0]\n",
    "y_ub = y_lane_bound[:, 1]\n",
    "param_des = data['param_des']\n",
    "dim_x_obs = data['dim_x_obs']\n",
    "dim_y_obs = data['dim_y_obs']\n",
    "psi_obs = data['psi_obs']\n",
    "\n",
    "# print(np.shape(dim_x_obs))\n",
    "\n",
    "\n",
    "dataset_size = np.shape(init_state_ego)[0]\n",
    "\n",
    "inp = np.hstack(( init_state_ego, goal_des, y_lane_bound   ))\n",
    "\n",
    "inp_mean, inp_std = inp.mean(), inp.std()\n",
    "\n",
    "\n",
    "pcd_data_temp = np.hstack(( closest_obs, dim_x_obs, dim_y_obs, v_obs, psi_obs  ))\n",
    "\n",
    "# pcd_data = closest_obs.reshape(dataset_size, 2, num_obs   )\n",
    "\n",
    "pcd_data = pcd_data_temp.reshape(dataset_size, 6, num_obs)\n",
    "\n",
    "\n",
    "# pcd_data = closest_obs.reshape(dataset_size, 2, num_obs   )\n",
    "\n",
    "min_pcd, max_pcd = pcd_data.min(), pcd_data.max()\n",
    "\n",
    "pcd_mean, pcd_std = pcd_data.mean(), pcd_data.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "\t\"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "\tdef __init__(self, inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs):\n",
    "\t\t\n",
    "\t\t# State Data\n",
    "\t\tself.inp = inp\n",
    "  \n",
    "\t\tself.init_state_ego = init_state_ego\n",
    "\t\t\n",
    "\t\t# PCD Data\n",
    "\t\tself.pcd_data = pcd_data\n",
    "\t\t\n",
    "\t\t# Expert Coeff\n",
    "\t\tself.param_des = param_des\n",
    "\t\t\n",
    "\t\tself.closest_obs = closest_obs\n",
    "  \n",
    "\t\tself.y_lane_bound = y_lane_bound\n",
    "\t\tself.goal_des = goal_des\n",
    "\t\tself.psi_obs = psi_obs \n",
    "\t\tself.dim_x_obs = dim_x_obs \n",
    "\t\tself.dim_y_obs = dim_y_obs\n",
    "\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inp)    \n",
    "\t\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\n",
    "\t\t# Inputs\n",
    "\t\tinp = self.inp[idx]\n",
    "\t\tinit_state_ego = self.inp[idx]\n",
    "\n",
    "\t\tpcd_data = self.pcd_data[idx]\n",
    "\t\t\n",
    "\t\t# Outputs\n",
    "\t\tparam_des = self.param_des[idx]\n",
    "\t\t\n",
    "\t\tclosest_obs = self.closest_obs[idx]\n",
    "  \n",
    "\t\ty_lane_bound = self.y_lane_bound[idx]\n",
    "\t\tgoal_des = self.goal_des[idx]\n",
    "\t\tdim_x_obs = self.dim_x_obs[idx]\n",
    "\t\tdim_y_obs = self.dim_y_obs[idx] \n",
    "\t\tpsi_obs = self.psi_obs[idx]\n",
    "\n",
    "  \n",
    "  \n",
    "\t\treturn torch.tensor(inp).float(), torch.tensor(init_state_ego).float(), torch.tensor(pcd_data).float(), torch.tensor(param_des).float(), torch.tensor(closest_obs).float(), torch.tensor(y_lane_bound).float(), torch.tensor(goal_des).float(),\\\n",
    "\t\t\t   torch.tensor(psi_obs).float(), torch.tensor(dim_x_obs).float(), torch.tensor(dim_y_obs).float()\t\t\n",
    "\n",
    "# Batch Size - 3k or 4k\n",
    "batch_size = 128\n",
    "\n",
    "# pcd_data = pcd_data.reshape(data_set_size, 2, 200)\n",
    "\n",
    "# Using PyTorch Dataloader\n",
    "train_dataset = TrajDataset(inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Differentiable Layer\n",
    "# num_batch = train_loader.batch_size\n",
    "\n",
    "P = P.to(device) \n",
    "Pdot = Pdot.to(device)\n",
    "P_diag = P_diag.to(device)\n",
    "Pddot_diag = Pddot_diag.to(device)\n",
    "\n",
    "# PointNet\n",
    "pcd_features = 40\n",
    "point_net = PointNet(inp_channel=6, emb_dims=1024, output_channels=pcd_features)\n",
    "\n",
    "\n",
    "# mlp_pred_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "# mlp_pred_hidden_dim = 256\n",
    "# mlp_pred_out_dim = 2*nvar \n",
    "\n",
    "\n",
    "# mlp_planner_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "# mlp_planner_out_dim = (2*nvar)**2+2*nvar\n",
    "# hidden_dim = 512\n",
    "\n",
    "\n",
    "mlp_init_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "mlp_init_hidden_dim = 256\n",
    "# mlp_init_out_dim = (2*nvar)**2+2*nvar+2*nvar\n",
    "mlp_init_out_dim = 4*nvar\n",
    "\n",
    "\n",
    "\n",
    "#########################33\n",
    "\n",
    "gru_input_size = 12*nvar\n",
    "# print(gru_input_size)\n",
    "gru_hidden_size = 512\n",
    "# gru_output_size = (2*nvar)**2+2*nvar\n",
    "gru_output_size = 4*nvar\n",
    "# gru_context_size = mlp_planner_inp_dim\n",
    "\n",
    "gru_context = CustomGRULayer(gru_input_size, gru_hidden_size, gru_output_size)\n",
    "# gru_context_primal = CustomGRULayer(gru_input_size, gru_hidden_size, gru_output_size)\n",
    "\n",
    "input_hidden_state_init = pcd_features+np.shape(inp)[1]\n",
    "mid_hidden_state_init = 512\n",
    "out_hidden_state_init = gru_hidden_size\n",
    "\n",
    "gru_hidden_state_init  =  GRU_Hidden_State(input_hidden_state_init, mid_hidden_state_init, out_hidden_state_init)\n",
    "# gru_hidden_state_init_primal  =  GRU_Hidden_State(input_hidden_state_init, mid_hidden_state_init, out_hidden_state_init)\n",
    "\n",
    "# mlp_pred = MLP_Pred(mlp_pred_inp_dim, mlp_pred_hidden_dim, mlp_pred_out_dim  )\n",
    "mlp_init = MLP_Init(mlp_init_inp_dim, mlp_init_hidden_dim, mlp_init_out_dim  )\n",
    "\n",
    "\n",
    "model = Learned_QCQP(num_obs, t_fin, P, Pdot, Pddot, point_net, num_batch, min_pcd, max_pcd, inp_mean, inp_std, gru_context, gru_hidden_state_init, mlp_init).to(device)\n",
    "# model.load_state_dict(torch.load('./weights/opt_surrogate_obs_avoidance_gru_new.pth'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 68.736, aug_loss_primal: 1.537, aug_loss_fixed_point: 67.199 \n",
      "Epoch: 5, Train Loss: 24.585, aug_loss_primal: 0.520, aug_loss_fixed_point: 24.064 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     42\u001b[39m y_obs = closest_obs[:, num_obs:\u001b[32m2\u001b[39m*num_obs]\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# with torch.autograd.detect_anomaly():\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m primal_sol, accumulated_res_primal, accumulated_res_fixed_point = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_state_ego\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_des\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcd_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mclosest_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_x_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_y_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43my_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPddot_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcd_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcd_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoal_des\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m loss, primal_loss, fixed_point_loss = model.ss_loss(accumulated_res_primal, primal_sol, accumulated_res_fixed_point)\n\u001b[32m     49\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learned_QCQP/training_scripts/models/learned_optim_qcqp_3.py:723\u001b[39m, in \u001b[36mLearned_QCQP.forward\u001b[39m\u001b[34m(self, inp, init_state_ego, param_des, pcd_data, closest_obs, psi_obs, dim_x_obs, dim_y_obs, y_ub, y_lb, P_diag, Pddot_diag, pcd_mean, pcd_std, goal_des)\u001b[39m\n\u001b[32m    718\u001b[39m pcd_scaled = (pcd_data - \u001b[38;5;28mself\u001b[39m.min_pcd) / (\u001b[38;5;28mself\u001b[39m.max_pcd - \u001b[38;5;28mself\u001b[39m.min_pcd)\n\u001b[32m    720\u001b[39m \u001b[38;5;66;03m# pcd_scaled = (pcd_data - pcd_mean) / (self.max_pcd - pcd_std)\u001b[39;00m\n\u001b[32m    721\u001b[39m \t\t\n\u001b[32m    722\u001b[39m \u001b[38;5;66;03m# Decode y\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m primal_sol, accumulated_res_primal, accumulated_res_fixed_point, res_primal_stack, res_fixed_point_stack = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_state_ego\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpcd_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_obs_circle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_obs_circle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_des\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoal_des\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;66;03m# predict_traj = (P_diag @ primal_sol.T).T\u001b[39;00m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# predict_acc = (Pddot_diag @ primal_sol.T).T\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m primal_sol, accumulated_res_primal, accumulated_res_fixed_point\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learned_QCQP/training_scripts/models/learned_optim_qcqp_3.py:689\u001b[39m, in \u001b[36mLearned_QCQP.decoder_function\u001b[39m\u001b[34m(self, inp_norm, init_state_ego, pcd_scaled, x_obs_circle_traj, y_obs_circle_traj, a_obs, b_obs, y_ub, y_lb, param_des, goal_des)\u001b[39m\n\u001b[32m    686\u001b[39m h_0 = \u001b[38;5;28mself\u001b[39m.gru_hidden_state_init(inp_features)\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# h_0_primal = self.gru_hidden_state_init(inp_features)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m primal_sol, accumulated_res_primal, accumulated_res_fixed_point, res_primal_stack, res_fixed_point_stack =  \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcustom_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_state_ego\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_obs_circle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_obs_circle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoal_des\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_x_guess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_y_guess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda_x_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda_y_init\u001b[49m\u001b[43m)\u001b[49m\t\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m primal_sol, accumulated_res_primal, accumulated_res_fixed_point, res_primal_stack, res_fixed_point_stack\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learned_QCQP/training_scripts/models/learned_optim_qcqp_3.py:617\u001b[39m, in \u001b[36mLearned_QCQP.custom_forward\u001b[39m\u001b[34m(self, init_state_ego, x_obs_circle_traj, y_obs_circle_traj, a_obs, b_obs, y_ub, y_lb, goal_des, c_x_guess, c_y_guess, h_0, lamda_x, lamda_y)\u001b[39m\n\u001b[32m    614\u001b[39m alpha_a, d_a, lamda_x, lamda_y, alpha_v, d_v, alpha_obs, d_obs, s_lane, res_norm_batch = \u001b[38;5;28mself\u001b[39m.compute_alpha_d(primal_sol, x_obs_circle_traj, y_obs_circle_traj, y_ub, y_lb, a_obs, b_obs, lamda_x, lamda_y)\n\u001b[32m    615\u001b[39m lamda = torch.hstack(( lamda_x, lamda_y  ))\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m primal_sol = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_x_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_eq_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_eq_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_obs_circle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_obs_circle_traj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamda_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_lane\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m r_1 = torch.hstack(( primal_sol_prev, lamda_prev)) \n\u001b[32m    622\u001b[39m r_2 = torch.hstack(( primal_sol, lamda))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/_functorch/apis.py:203\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/_functorch/vmap.py:331\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    321\u001b[39m         func,\n\u001b[32m    322\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m         **kwargs,\n\u001b[32m    328\u001b[39m     )\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/_functorch/vmap.py:479\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    476\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    477\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learned_QCQP/training_scripts/models/learned_optim_qcqp_3.py:583\u001b[39m, in \u001b[36mLearned_QCQP.compute_x\u001b[39m\u001b[34m(self, b_eq_x, b_eq_y, x_obs_circle_traj, y_obs_circle_traj, a_obs, b_obs, lamda_x, lamda_y, alpha_obs, d_obs, alpha_a, d_a, alpha_v, d_v, y_ub, y_lb, s_lane)\u001b[39m\n\u001b[32m    579\u001b[39m cost_mat_y = torch.vstack([torch.hstack([cost_y, \u001b[38;5;28mself\u001b[39m.A_eq_y.T]), torch.hstack([\u001b[38;5;28mself\u001b[39m.A_eq_y, torch.zeros((\u001b[38;5;28mself\u001b[39m.A_eq_y.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.A_eq_y.shape[\u001b[32m0\u001b[39m]), device=device)])])\n\u001b[32m    582\u001b[39m sol_x = torch.linalg.solve(cost_mat_x+\u001b[32m0.0000\u001b[39m*torch.eye( cost_mat_x.size(dim = \u001b[32m1\u001b[39m), device = device  ), torch.hstack(( -lincost_x, b_eq_x )))\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m sol_y = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost_mat_y\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m0.0000\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_mat_y\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43mlincost_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_eq_y\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m primal_sol_x = sol_x[\u001b[32m0\u001b[39m:\u001b[38;5;28mself\u001b[39m.nvar]\n\u001b[32m    587\u001b[39m primal_sol_y = sol_y[\u001b[32m0\u001b[39m:\u001b[38;5;28mself\u001b[39m.nvar]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 1000\n",
    "step = 0 \n",
    "beta = 1.0 # 3.5\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-4, weight_decay=6e-5)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr = 1e-3, weight_decay=6e-5)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma = 0.1)\n",
    "\n",
    "avg_train_loss, avg_loss_primal, avg_fixed_point_loss = [], [], []\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "\t\n",
    "\t# Train Loop\n",
    "\tlosses_train, aug_losses_primal, aug_losses_fixed_point = [], [], []\n",
    "\t\n",
    "\tfor (inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs) in train_loader:\n",
    "\t\t\n",
    "\t\t# Input and Output \n",
    "  \n",
    "\t\t################################################################################################\n",
    "\n",
    "\t\t# print(goal_des[0])\n",
    "\t\t# print(y_lb[0], y_ub[0])\n",
    "\n",
    "  \n",
    "\t\tinp = inp.to(device)\n",
    "\t\tinit_state_ego = init_state_ego.to(device)\n",
    "\t\tparam_des = param_des.to(device)\n",
    "\n",
    "\t\tpcd_data = pcd_data.to(device)\n",
    "\t\tclosest_obs = closest_obs.to(device)\n",
    "\t\ty_lane_bound = y_lane_bound.to(device)\n",
    "\t\ty_lb = y_lane_bound[:, 0]\n",
    "\t\ty_ub = y_lane_bound[:, 1]\n",
    "\t\tgoal_des = goal_des.to(device)\n",
    "\t\tpsi_obs = psi_obs.to(device)\n",
    "\t\tdim_x_obs = dim_x_obs.to(device)\n",
    "\t\tdim_y_obs = dim_y_obs.to(device)\n",
    "  \n",
    "\t\tx_obs = closest_obs[:, 0:num_obs]\n",
    "\t\ty_obs = closest_obs[:, num_obs:2*num_obs]\n",
    "\t\t\n",
    "\t\t# with torch.autograd.detect_anomaly():\n",
    "  \n",
    "\t\tprimal_sol, accumulated_res_primal, accumulated_res_fixed_point = model(inp, init_state_ego, param_des, pcd_data,  closest_obs, psi_obs, dim_x_obs, dim_y_obs,  y_ub, y_lb, P_diag, Pddot_diag, pcd_mean, pcd_std, goal_des)\n",
    "\t\tloss, primal_loss, fixed_point_loss = model.ss_loss(accumulated_res_primal, primal_sol, accumulated_res_fixed_point)\n",
    "\t\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tlosses_train.append(loss.detach().cpu().numpy()) \n",
    "\t\taug_losses_primal.append(primal_loss.detach().cpu().numpy())\n",
    "\t\taug_losses_fixed_point.append(fixed_point_loss.detach().cpu().numpy())\n",
    "\t\t# aug_losses_res.append(res_loss.detach().cpu().numpy())\n",
    "\t\t# aug_losses_steer.append(steer_loss.detach().cpu().numpy())\n",
    "\n",
    "\t\t\n",
    "\t# scale = scale*1.2\t\n",
    "\t\t\n",
    "\tif epoch % 4 == 0:    \n",
    "\t\tprint(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, aug_loss_primal: {np.average(aug_losses_primal):.3f}, aug_loss_fixed_point: {np.average(aug_losses_fixed_point):.3f} \")\n",
    "\n",
    "\tstep += 0.15 #0.15\n",
    "\t# scheduler.step()\n",
    "\tavg_train_loss.append(np.average(losses_train)), avg_loss_primal.append(np.average(aug_losses_primal)), avg_fixed_point_loss.append(np.average(aug_losses_fixed_point))\n",
    "\t\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './weights/opt_surrogate_obs_avoidance_gru_new.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
