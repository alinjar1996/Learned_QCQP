{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# %matplotlib widget\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch_optimizer as optim_custom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.bernstein_torch import bernstein_coeff_order10_new\n",
    "# import scipy.io as sio\n",
    "\n",
    "# from models.mlp_qp_vis_aware_2 import MLP, vis_aware_track_net, PointNet\n",
    "# import pol_matrix_comp\n",
    "# from tqdm import trange\n",
    "\n",
    "from models.learned_optim_qcqp_2 import PointNet, CustomGRULayer, GRU_Hidden_State, MLP_Init, Learned_QCQP\n",
    "from scipy.io import loadmat\n",
    "import pol_matrix_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_fin = 10.0\n",
    "num = 100\n",
    "tot_time = np.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "\n",
    "\n",
    "P_np, Pdot_np, Pddot_np = pol_matrix_comp.pol_matrix_comp(tot_time_copy)\n",
    "\n",
    "nvar = np.shape(P_np)[1]\n",
    "\n",
    "P = torch.from_numpy(P_np).float()\n",
    "Pdot = torch.from_numpy(Pdot_np).float()\n",
    "Pddot = torch.from_numpy(Pddot_np).float()\n",
    "\n",
    "P_diag = torch.block_diag(P, P)\n",
    "Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "\n",
    "\n",
    "num_obs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = loadmat('./dataset/goal_reaching_dataset_4.mat')\n",
    "\n",
    "init_state_ego = data['init_state_ego']\n",
    "goal_des = data['goal_des']\n",
    "closest_obs = data['closest_obs']\n",
    "v_obs = data['v_obs']\n",
    "y_lane_bound = data['y_lane_bound']\n",
    "y_lb = y_lane_bound[:, 0]\n",
    "y_ub = y_lane_bound[:, 1]\n",
    "param_des = data['param_des']\n",
    "dim_x_obs = data['dim_x_obs']\n",
    "dim_y_obs = data['dim_y_obs']\n",
    "psi_obs = data['psi_obs']\n",
    "\n",
    "# print(np.shape(dim_x_obs))\n",
    "\n",
    "\n",
    "dataset_size = np.shape(init_state_ego)[0]\n",
    "\n",
    "inp = np.hstack(( init_state_ego, goal_des, y_lane_bound   ))\n",
    "\n",
    "inp_mean, inp_std = inp.mean(), inp.std()\n",
    "\n",
    "\n",
    "pcd_data_temp = np.hstack(( closest_obs, dim_x_obs, dim_y_obs, v_obs, psi_obs  ))\n",
    "\n",
    "# pcd_data = closest_obs.reshape(dataset_size, 2, num_obs   )\n",
    "\n",
    "pcd_data = pcd_data_temp.reshape(dataset_size, 6, num_obs)\n",
    "\n",
    "\n",
    "# pcd_data = closest_obs.reshape(dataset_size, 2, num_obs   )\n",
    "\n",
    "min_pcd, max_pcd = pcd_data.min(), pcd_data.max()\n",
    "\n",
    "pcd_mean, pcd_std = pcd_data.mean(), pcd_data.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "\t\"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "\tdef __init__(self, inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs):\n",
    "\t\t\n",
    "\t\t# State Data\n",
    "\t\tself.inp = inp\n",
    "  \n",
    "\t\tself.init_state_ego = init_state_ego\n",
    "\t\t\n",
    "\t\t# PCD Data\n",
    "\t\tself.pcd_data = pcd_data\n",
    "\t\t\n",
    "\t\t# Expert Coeff\n",
    "\t\tself.param_des = param_des\n",
    "\t\t\n",
    "\t\tself.closest_obs = closest_obs\n",
    "  \n",
    "\t\tself.y_lane_bound = y_lane_bound\n",
    "\t\tself.goal_des = goal_des\n",
    "\t\tself.psi_obs = psi_obs \n",
    "\t\tself.dim_x_obs = dim_x_obs \n",
    "\t\tself.dim_y_obs = dim_y_obs\n",
    "\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inp)    \n",
    "\t\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\n",
    "\t\t# Inputs\n",
    "\t\tinp = self.inp[idx]\n",
    "\t\tinit_state_ego = self.inp[idx]\n",
    "\n",
    "\t\tpcd_data = self.pcd_data[idx]\n",
    "\t\t\n",
    "\t\t# Outputs\n",
    "\t\tparam_des = self.param_des[idx]\n",
    "\t\t\n",
    "\t\tclosest_obs = self.closest_obs[idx]\n",
    "  \n",
    "\t\ty_lane_bound = self.y_lane_bound[idx]\n",
    "\t\tgoal_des = self.goal_des[idx]\n",
    "\t\tdim_x_obs = self.dim_x_obs[idx]\n",
    "\t\tdim_y_obs = self.dim_y_obs[idx] \n",
    "\t\tpsi_obs = self.psi_obs[idx]\n",
    "\n",
    "  \n",
    "  \n",
    "\t\treturn torch.tensor(inp).float(), torch.tensor(init_state_ego).float(), torch.tensor(pcd_data).float(), torch.tensor(param_des).float(), torch.tensor(closest_obs).float(), torch.tensor(y_lane_bound).float(), torch.tensor(goal_des).float(),\\\n",
    "\t\t\t   torch.tensor(psi_obs).float(), torch.tensor(dim_x_obs).float(), torch.tensor(dim_y_obs).float()\t\t\n",
    "\n",
    "# Batch Size - 3k or 4k\n",
    "batch_size = 256\n",
    "\n",
    "# pcd_data = pcd_data.reshape(data_set_size, 2, 200)\n",
    "\n",
    "# Using PyTorch Dataloader\n",
    "train_dataset = TrajDataset(inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Differentiable Layer\n",
    "num_batch = train_loader.batch_size\n",
    "\n",
    "P = P.to(device) \n",
    "Pdot = Pdot.to(device)\n",
    "P_diag = P_diag.to(device)\n",
    "Pddot_diag = Pddot_diag.to(device)\n",
    "\n",
    "# PointNet\n",
    "pcd_features = 40\n",
    "point_net = PointNet(inp_channel=6, emb_dims=1024, output_channels=pcd_features)\n",
    "\n",
    "\n",
    "# mlp_pred_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "# mlp_pred_hidden_dim = 256\n",
    "# mlp_pred_out_dim = 2*nvar \n",
    "\n",
    "\n",
    "# mlp_planner_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "# mlp_planner_out_dim = (2*nvar)**2+2*nvar\n",
    "# hidden_dim = 512\n",
    "\n",
    "\n",
    "mlp_init_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "mlp_init_hidden_dim = 256\n",
    "mlp_init_out_dim = (2*nvar)**2+2*nvar \n",
    "\n",
    "\n",
    "#########################33\n",
    "\n",
    "gru_input_size = 2*nvar+1 \n",
    "# print(gru_input_size)\n",
    "gru_hidden_size = 512\n",
    "gru_output_size = (2*nvar)**2+2*nvar\n",
    "# gru_context_size = mlp_planner_inp_dim\n",
    "\n",
    "gru_context = CustomGRULayer(gru_input_size, gru_hidden_size, gru_output_size)\n",
    "\n",
    "input_hidden_state_init = pcd_features+np.shape(inp)[1]\n",
    "mid_hidden_state_init = 512\n",
    "out_hidden_state_init = gru_hidden_size\n",
    "\n",
    "gru_hidden_state_init  =  GRU_Hidden_State(input_hidden_state_init, mid_hidden_state_init, out_hidden_state_init)\n",
    "\n",
    "\n",
    "# mlp_pred = MLP_Pred(mlp_pred_inp_dim, mlp_pred_hidden_dim, mlp_pred_out_dim  )\n",
    "mlp_init = MLP_Init(mlp_init_inp_dim, mlp_init_hidden_dim, mlp_init_out_dim  )\n",
    "\n",
    "\n",
    "model = Learned_QCQP(num_obs, t_fin, P, Pdot, Pddot, point_net, num_batch, min_pcd, max_pcd, inp_mean, inp_std, gru_context, gru_hidden_state_init, mlp_init).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 2.316 \n",
      "Epoch: 5, Train Loss: 0.491 \n",
      "Epoch: 9, Train Loss: 0.135 \n",
      "Epoch: 13, Train Loss: 0.076 \n",
      "Epoch: 17, Train Loss: 0.105 \n",
      "Epoch: 21, Train Loss: 0.047 \n",
      "Epoch: 25, Train Loss: 0.041 \n",
      "Epoch: 29, Train Loss: 0.050 \n",
      "Epoch: 33, Train Loss: 0.044 \n",
      "Epoch: 37, Train Loss: 0.036 \n",
      "Epoch: 41, Train Loss: 0.034 \n",
      "Epoch: 45, Train Loss: 0.034 \n",
      "Epoch: 49, Train Loss: 0.033 \n",
      "Epoch: 53, Train Loss: 0.033 \n",
      "Epoch: 57, Train Loss: 0.039 \n",
      "Epoch: 61, Train Loss: 0.038 \n",
      "Epoch: 65, Train Loss: 0.036 \n",
      "Epoch: 69, Train Loss: 0.035 \n",
      "Epoch: 73, Train Loss: 0.035 \n",
      "Epoch: 77, Train Loss: 0.035 \n",
      "Epoch: 81, Train Loss: 0.035 \n",
      "Epoch: 85, Train Loss: 0.030 \n",
      "Epoch: 89, Train Loss: 0.037 \n",
      "Epoch: 93, Train Loss: 0.033 \n",
      "Epoch: 97, Train Loss: 0.038 \n",
      "Epoch: 101, Train Loss: 0.027 \n",
      "Epoch: 105, Train Loss: 0.030 \n",
      "Epoch: 109, Train Loss: 0.036 \n",
      "Epoch: 113, Train Loss: 0.038 \n",
      "Epoch: 117, Train Loss: 0.029 \n",
      "Epoch: 121, Train Loss: 0.034 \n",
      "Epoch: 125, Train Loss: 0.036 \n",
      "Epoch: 129, Train Loss: 0.030 \n",
      "Epoch: 133, Train Loss: 0.025 \n",
      "Epoch: 137, Train Loss: 0.034 \n",
      "Epoch: 141, Train Loss: 0.039 \n",
      "Epoch: 145, Train Loss: 0.035 \n",
      "Epoch: 149, Train Loss: 0.034 \n",
      "Epoch: 153, Train Loss: 0.029 \n",
      "Epoch: 157, Train Loss: 0.029 \n",
      "Epoch: 161, Train Loss: 0.032 \n",
      "Epoch: 165, Train Loss: 0.035 \n",
      "Epoch: 169, Train Loss: 0.036 \n",
      "Epoch: 173, Train Loss: 0.059 \n",
      "Epoch: 177, Train Loss: 0.039 \n",
      "Epoch: 181, Train Loss: 0.031 \n",
      "Epoch: 185, Train Loss: 0.035 \n",
      "Epoch: 189, Train Loss: 0.036 \n",
      "Epoch: 193, Train Loss: 0.034 \n",
      "Epoch: 197, Train Loss: 0.032 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 200\n",
    "step = 0 \n",
    "beta = 1.0 # 3.5\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-3, weight_decay=6e-5)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr = 2e-3, weight_decay=6e-5)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 70, gamma = 0.1)\n",
    "\n",
    "avg_train_loss = []\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "\t\n",
    "\t# Train Loop\n",
    "\tlosses_train = []\n",
    "\t\n",
    "\tfor (inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs) in train_loader:\n",
    "\t\t\n",
    "\t\t# Input and Output \n",
    "  \n",
    "\t\t################################################################################################\n",
    "\n",
    "\t\t# print(goal_des[0])\n",
    "\t\t# print(y_lb[0], y_ub[0])\n",
    "\n",
    "  \n",
    "\t\tinp = inp.to(device)\n",
    "\t\tinit_state_ego = init_state_ego.to(device)\n",
    "\t\tparam_des = param_des.to(device)\n",
    "\n",
    "\t\tpcd_data = pcd_data.to(device)\n",
    "\t\tclosest_obs = closest_obs.to(device)\n",
    "\t\ty_lane_bound = y_lane_bound.to(device)\n",
    "\t\ty_lb = y_lane_bound[:, 0]\n",
    "\t\ty_ub = y_lane_bound[:, 1]\n",
    "\t\tgoal_des = goal_des.to(device)\n",
    "\t\tpsi_obs = psi_obs.to(device)\n",
    "\t\tdim_x_obs = dim_x_obs.to(device)\n",
    "\t\tdim_y_obs = dim_y_obs.to(device)\n",
    "  \n",
    "\t\tx_obs = closest_obs[:, 0:num_obs]\n",
    "\t\ty_obs = closest_obs[:, num_obs:2*num_obs]\n",
    "\t\t\n",
    "  \n",
    "\t\tprimal_sol, accumulated_res_primal = model(inp, init_state_ego, param_des, pcd_data,  closest_obs, psi_obs, dim_x_obs, dim_y_obs,  y_ub, y_lb, P_diag, Pddot_diag, pcd_mean, pcd_std, goal_des)\n",
    "\t\tloss = model.ss_loss(accumulated_res_primal, primal_sol)\n",
    "\t \n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tlosses_train.append(loss.detach().cpu().numpy()) \n",
    "\t\t# aug_losses_primal.append(primal_loss.detach().cpu().numpy())\n",
    "\t\t# aug_losses_fixed_point.append(fixed_point_loss.detach().cpu().numpy())\n",
    "\t\t# aug_losses_res.append(res_loss.detach().cpu().numpy())\n",
    "\t\t\n",
    "\t# scale = scale*1.2\t\n",
    "\t\t\n",
    "\tif epoch % 4 == 0:    \n",
    "\t\tprint(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f} \")\n",
    "\n",
    "\tstep += 0.15 #0.15\n",
    "\t# scheduler.step()\n",
    "\tavg_train_loss.append(np.average(losses_train))\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './weights/opt_surrogate_obs_avoidance_gru.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
