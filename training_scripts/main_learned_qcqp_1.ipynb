{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "# import torch_optimizer as optim_custom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.bernstein_torch import bernstein_coeff_order10_new\n",
    "# import scipy.io as sio\n",
    "\n",
    "# from models.mlp_qp_vis_aware_2 import MLP, vis_aware_track_net, PointNet\n",
    "# import pol_matrix_comp\n",
    "# from tqdm import trange\n",
    "\n",
    "from models.learned_optim_qcqp_1 import PointNet, CustomGRULayer, GRU_Hidden_State, MLP_Pred, MLP_Init, Learned_QCQP\n",
    "from scipy.io import loadmat\n",
    "import pol_matrix_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_fin = 10.0\n",
    "# num = 100\n",
    "# tot_time = np.linspace(0, t_fin, num)\n",
    "# tot_time_copy = tot_time.reshape(num, 1)\n",
    "\n",
    "\n",
    "# P_np, Pdot_np, Pddot_np = pol_matrix_comp.pol_matrix_comp(tot_time_copy)\n",
    "\n",
    "# nvar = np.shape(P_np)[1]\n",
    "\n",
    "# P = torch.from_numpy(P_np).float()\n",
    "# Pdot = torch.from_numpy(Pdot_np).float()\n",
    "# Pddot = torch.from_numpy(Pddot_np).float()\n",
    "\n",
    "# P_diag = torch.block_diag(P, P)\n",
    "# Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "\n",
    "\n",
    "\n",
    "t_fin = 10.0\n",
    "num = 100\n",
    "tot_time = torch.linspace(0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "P_diag = torch.block_diag(P, P)\n",
    "Pddot_diag = torch.block_diag(Pddot, Pddot)\n",
    "\n",
    "nvar = np.shape(P)[1]\n",
    "num_obs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('./dataset/goal_reaching_dataset_4.mat')\n",
    "\n",
    "init_state_ego = data['init_state_ego']\n",
    "goal_des = data['goal_des']\n",
    "closest_obs = data['closest_obs']\n",
    "v_obs = data['v_obs']\n",
    "y_lane_bound = data['y_lane_bound']\n",
    "y_lb = y_lane_bound[:, 0]\n",
    "y_ub = y_lane_bound[:, 1]\n",
    "param_des = data['param_des']\n",
    "dim_x_obs = data['dim_x_obs']\n",
    "dim_y_obs = data['dim_y_obs']\n",
    "psi_obs = data['psi_obs']\n",
    "\n",
    "# print(np.shape(dim_x_obs))\n",
    "\n",
    "\n",
    "dataset_size = np.shape(init_state_ego)[0]\n",
    "\n",
    "inp = np.hstack(( init_state_ego, param_des, y_lane_bound   ))\n",
    "\n",
    "inp_mean, inp_std = inp.mean(), inp.std()\n",
    "\n",
    "\n",
    "pcd_data = closest_obs.reshape(dataset_size, 2, num_obs   )\n",
    "\n",
    "min_pcd, max_pcd = pcd_data.min(), pcd_data.max()\n",
    "\n",
    "pcd_mean, pcd_std = pcd_data.mean(), pcd_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Loader \n",
    "class TrajDataset(Dataset):\n",
    "\t\"\"\"Expert Trajectory Dataset.\"\"\"\n",
    "\tdef __init__(self, inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs):\n",
    "\t\t\n",
    "\t\t# State Data\n",
    "\t\tself.inp = inp\n",
    "  \n",
    "\t\tself.init_state_ego = init_state_ego\n",
    "\t\t\n",
    "\t\t# PCD Data\n",
    "\t\tself.pcd_data = pcd_data\n",
    "\t\t\n",
    "\t\t# Expert Coeff\n",
    "\t\tself.param_des = param_des\n",
    "\t\t\n",
    "\t\tself.closest_obs = closest_obs\n",
    "  \n",
    "\t\tself.y_lane_bound = y_lane_bound\n",
    "\t\tself.goal_des = goal_des\n",
    "\t\tself.psi_obs = psi_obs \n",
    "\t\tself.dim_x_obs = dim_x_obs \n",
    "\t\tself.dim_y_obs = dim_y_obs\n",
    "\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.inp)    \n",
    "\t\t\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\t\n",
    "\t\t# Inputs\n",
    "\t\tinp = self.inp[idx]\n",
    "\t\tinit_state_ego = self.inp[idx]\n",
    "\n",
    "\t\tpcd_data = self.pcd_data[idx]\n",
    "\t\t\n",
    "\t\t# Outputs\n",
    "\t\tparam_des = self.param_des[idx]\n",
    "\t\t\n",
    "\t\tclosest_obs = self.closest_obs[idx]\n",
    "  \n",
    "\t\ty_lane_bound = self.y_lane_bound[idx]\n",
    "\t\tgoal_des = self.goal_des[idx]\n",
    "\t\tdim_x_obs = self.dim_x_obs[idx]\n",
    "\t\tdim_y_obs = self.dim_y_obs[idx] \n",
    "\t\tpsi_obs = self.psi_obs[idx]\n",
    "\n",
    "  \n",
    "  \n",
    "\t\treturn torch.tensor(inp).float(), torch.tensor(init_state_ego).float(), torch.tensor(pcd_data).float(), torch.tensor(param_des).float(), torch.tensor(closest_obs).float(), torch.tensor(y_lane_bound).float(), torch.tensor(goal_des).float(),\\\n",
    "\t\t\t   torch.tensor(psi_obs).float(), torch.tensor(dim_x_obs).float(), torch.tensor(dim_y_obs).float()\t\t\n",
    "\n",
    "# Batch Size - 3k or 4k\n",
    "batch_size = 256\n",
    "\n",
    "# pcd_data = pcd_data.reshape(data_set_size, 2, 200)\n",
    "\n",
    "# Using PyTorch Dataloader\n",
    "train_dataset = TrajDataset(inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiable Layer\n",
    "num_batch = train_loader.batch_size\n",
    "\n",
    "P = P.to(device) \n",
    "Pdot = Pdot.to(device)\n",
    "P_diag = P_diag.to(device)\n",
    "Pddot_diag = Pddot_diag.to(device)\n",
    "\n",
    "# PointNet\n",
    "pcd_features = 40\n",
    "point_net = PointNet(inp_channel=2, emb_dims=1024, output_channels=pcd_features)\n",
    "\n",
    "\n",
    "mlp_pred_inp_dim = np.shape(inp)[1]+pcd_features\n",
    "mlp_pred_hidden_dim = 256\n",
    "mlp_pred_out_dim = 2*nvar \n",
    "\n",
    "\n",
    "mlp_init_inp_dim = np.shape(inp)[1]+pcd_features+2*nvar\n",
    "mlp_init_hidden_dim = 256\n",
    "mlp_init_out_dim = 4*nvar \n",
    "\n",
    "\n",
    "#########################33\n",
    "\n",
    "gru_input_size = 12*nvar \n",
    "# print(gru_input_size)\n",
    "gru_hidden_size = 512\n",
    "gru_output_size = 4*nvar \n",
    "# gru_context_size = mlp_planner_inp_dim\n",
    "\n",
    "gru_context = CustomGRULayer(gru_input_size, gru_hidden_size, gru_output_size)\n",
    "\n",
    "input_hidden_state_init = pcd_features+np.shape(inp)[1]+2*nvar\n",
    "mid_hidden_state_init = 512\n",
    "out_hidden_state_init = gru_hidden_size\n",
    "\n",
    "gru_hidden_state_init  =  GRU_Hidden_State(input_hidden_state_init, mid_hidden_state_init, out_hidden_state_init)\n",
    "\n",
    "\n",
    "mlp_pred = MLP_Pred(mlp_pred_inp_dim, mlp_pred_hidden_dim, mlp_pred_out_dim  )\n",
    "mlp_init = MLP_Init(mlp_init_inp_dim, mlp_init_hidden_dim, mlp_init_out_dim  )\n",
    "\n",
    "\n",
    "model = Learned_QCQP(num_obs, t_fin, P, Pdot, Pddot, point_net, num_batch, min_pcd, max_pcd, inp_mean, inp_std, gru_context, gru_hidden_state_init, mlp_pred, mlp_init).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 12.847, aug_loss_primal: 3.185, aug_loss_fixed_point: 6.697, res_loss: 51.428, steer_loss: 1.007 \n",
      "Epoch: 5, Train Loss: 4.027, aug_loss_primal: 0.286, aug_loss_fixed_point: 2.553, res_loss: 14.041, steer_loss: 0.070 \n",
      "Epoch: 9, Train Loss: 3.230, aug_loss_primal: 0.190, aug_loss_fixed_point: 2.336, res_loss: 8.475, steer_loss: 0.046 \n",
      "Epoch: 13, Train Loss: 3.562, aug_loss_primal: 0.284, aug_loss_fixed_point: 2.676, res_loss: 8.127, steer_loss: 0.073 \n",
      "Epoch: 17, Train Loss: 2.983, aug_loss_primal: 0.156, aug_loss_fixed_point: 2.260, res_loss: 6.754, steer_loss: 0.047 \n",
      "Epoch: 21, Train Loss: 2.795, aug_loss_primal: 0.122, aug_loss_fixed_point: 2.135, res_loss: 6.154, steer_loss: 0.044 \n",
      "Epoch: 25, Train Loss: 2.694, aug_loss_primal: 0.101, aug_loss_fixed_point: 2.044, res_loss: 6.068, steer_loss: 0.043 \n",
      "Epoch: 29, Train Loss: 2.624, aug_loss_primal: 0.082, aug_loss_fixed_point: 1.976, res_loss: 6.032, steer_loss: 0.044 \n",
      "Epoch: 33, Train Loss: 2.528, aug_loss_primal: 0.064, aug_loss_fixed_point: 1.935, res_loss: 5.494, steer_loss: 0.043 \n",
      "Epoch: 37, Train Loss: 2.448, aug_loss_primal: 0.046, aug_loss_fixed_point: 1.889, res_loss: 5.182, steer_loss: 0.041 \n",
      "Epoch: 41, Train Loss: 2.375, aug_loss_primal: 0.031, aug_loss_fixed_point: 1.802, res_loss: 5.328, steer_loss: 0.040 \n",
      "Epoch: 45, Train Loss: 2.352, aug_loss_primal: 0.018, aug_loss_fixed_point: 1.789, res_loss: 5.263, steer_loss: 0.036 \n",
      "Epoch: 49, Train Loss: 2.326, aug_loss_primal: 0.016, aug_loss_fixed_point: 1.675, res_loss: 6.083, steer_loss: 0.042 \n",
      "Epoch: 53, Train Loss: 2.174, aug_loss_primal: 0.008, aug_loss_fixed_point: 1.636, res_loss: 5.022, steer_loss: 0.036 \n",
      "Epoch: 57, Train Loss: 2.118, aug_loss_primal: 0.007, aug_loss_fixed_point: 1.597, res_loss: 4.868, steer_loss: 0.035 \n",
      "Epoch: 61, Train Loss: 2.033, aug_loss_primal: 0.010, aug_loss_fixed_point: 1.546, res_loss: 4.530, steer_loss: 0.034 \n",
      "Epoch: 65, Train Loss: 1.949, aug_loss_primal: 0.007, aug_loss_fixed_point: 1.453, res_loss: 4.635, steer_loss: 0.032 \n",
      "Epoch: 69, Train Loss: 1.890, aug_loss_primal: 0.009, aug_loss_fixed_point: 1.442, res_loss: 4.171, steer_loss: 0.031 \n",
      "Epoch: 73, Train Loss: 1.802, aug_loss_primal: 0.007, aug_loss_fixed_point: 1.319, res_loss: 4.503, steer_loss: 0.032 \n",
      "Epoch: 77, Train Loss: 1.698, aug_loss_primal: 0.009, aug_loss_fixed_point: 1.259, res_loss: 4.088, steer_loss: 0.030 \n",
      "Epoch: 81, Train Loss: 1.593, aug_loss_primal: 0.007, aug_loss_fixed_point: 1.128, res_loss: 4.347, steer_loss: 0.030 \n",
      "Epoch: 85, Train Loss: 1.526, aug_loss_primal: 0.011, aug_loss_fixed_point: 1.108, res_loss: 3.890, steer_loss: 0.029 \n",
      "Epoch: 89, Train Loss: 1.429, aug_loss_primal: 0.018, aug_loss_fixed_point: 0.989, res_loss: 4.107, steer_loss: 0.029 \n",
      "Epoch: 93, Train Loss: 1.244, aug_loss_primal: 0.007, aug_loss_fixed_point: 0.853, res_loss: 3.633, steer_loss: 0.028 \n",
      "Epoch: 97, Train Loss: 1.098, aug_loss_primal: 0.008, aug_loss_fixed_point: 0.743, res_loss: 3.281, steer_loss: 0.027 \n",
      "Epoch: 101, Train Loss: 0.997, aug_loss_primal: 0.006, aug_loss_fixed_point: 0.670, res_loss: 3.013, steer_loss: 0.025 \n",
      "Epoch: 105, Train Loss: 0.974, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.667, res_loss: 2.823, steer_loss: 0.025 \n",
      "Epoch: 109, Train Loss: 0.965, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.655, res_loss: 2.852, steer_loss: 0.024 \n",
      "Epoch: 113, Train Loss: 0.954, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.639, res_loss: 2.904, steer_loss: 0.024 \n",
      "Epoch: 117, Train Loss: 0.930, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.636, res_loss: 2.701, steer_loss: 0.024 \n",
      "Epoch: 121, Train Loss: 0.918, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.628, res_loss: 2.667, steer_loss: 0.024 \n",
      "Epoch: 125, Train Loss: 0.895, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.617, res_loss: 2.549, steer_loss: 0.024 \n",
      "Epoch: 129, Train Loss: 0.895, aug_loss_primal: 0.004, aug_loss_fixed_point: 0.603, res_loss: 2.682, steer_loss: 0.024 \n",
      "Epoch: 133, Train Loss: 0.883, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.588, res_loss: 2.710, steer_loss: 0.024 \n",
      "Epoch: 137, Train Loss: 0.887, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.571, res_loss: 2.918, steer_loss: 0.024 \n",
      "Epoch: 141, Train Loss: 0.838, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.568, res_loss: 2.462, steer_loss: 0.023 \n",
      "Epoch: 145, Train Loss: 0.845, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.572, res_loss: 2.502, steer_loss: 0.023 \n",
      "Epoch: 149, Train Loss: 0.841, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.557, res_loss: 2.611, steer_loss: 0.023 \n",
      "Epoch: 153, Train Loss: 0.805, aug_loss_primal: 0.005, aug_loss_fixed_point: 0.548, res_loss: 2.343, steer_loss: 0.023 \n",
      "Epoch: 157, Train Loss: 0.806, aug_loss_primal: 0.004, aug_loss_fixed_point: 0.541, res_loss: 2.428, steer_loss: 0.023 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m loss, fixed_point_loss, primal_loss, res_loss, steer_loss = model.ss_loss(accumulated_res_primal, accumulated_res_fixed_point, primal_sol, param_des, Pddot_diag, c_pred)\n\u001b[32m     48\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m optimizer.step()\n\u001b[32m     52\u001b[39m losses_train.append(loss.detach().cpu().numpy()) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/amith/torch_jax_env/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 800\n",
    "step = 0 \n",
    "beta = 1.0 # 3.5\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 1e-3, weight_decay=6e-5)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr = 2e-3, weight_decay=6e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 100, gamma = 0.1)\n",
    "\n",
    "avg_train_loss, avg_loss_primal, avg_fixed_point_loss, avg_res_loss, avg_steer_loss = [], [], [], [], []\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "\t\n",
    "\t# Train Loop\n",
    "\tlosses_train, aug_losses_primal, aug_losses_fixed_point, aug_losses_res, aug_losses_steer = [], [], [], [], []\n",
    "\t\n",
    "\tfor (inp, init_state_ego, pcd_data, param_des, closest_obs, y_lane_bound, goal_des, psi_obs, dim_x_obs, dim_y_obs) in train_loader:\n",
    "\t\t\n",
    "\t\t# Input and Output \n",
    "  \n",
    "\t\t################################################################################################\n",
    "\n",
    "\t\t# print(goal_des[0])\n",
    "\t\t# print(y_lb[0], y_ub[0])\n",
    "\n",
    "  \n",
    "\t\tinp = inp.to(device)\n",
    "\t\tinit_state_ego = init_state_ego.to(device)\n",
    "\t\tparam_des = param_des.to(device)\n",
    "\n",
    "\t\tpcd_data = pcd_data.to(device)\n",
    "\t\tclosest_obs = closest_obs.to(device)\n",
    "\t\ty_lane_bound = y_lane_bound.to(device)\n",
    "\t\ty_lb = y_lane_bound[:, 0]\n",
    "\t\ty_ub = y_lane_bound[:, 1]\n",
    "\t\tgoal_des = goal_des.to(device)\n",
    "\t\tpsi_obs = psi_obs.to(device)\n",
    "\t\tdim_x_obs = dim_x_obs.to(device)\n",
    "\t\tdim_y_obs = dim_y_obs.to(device)\n",
    "  \n",
    "\t\tx_obs = closest_obs[:, 0:num_obs]\n",
    "\t\ty_obs = closest_obs[:, num_obs:2*num_obs]\n",
    "\t\t\n",
    "  \n",
    "\t\tprimal_sol, accumulated_res_primal, accumulated_res_fixed_point, c_pred = model(inp, init_state_ego, pcd_data,  closest_obs, psi_obs, dim_x_obs, dim_y_obs,  y_ub, y_lb)\n",
    "\t\tloss, fixed_point_loss, primal_loss, res_loss, steer_loss = model.ss_loss(accumulated_res_primal, accumulated_res_fixed_point, primal_sol, param_des, Pddot_diag, c_pred)\n",
    "\t \n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tlosses_train.append(loss.detach().cpu().numpy()) \n",
    "\t\taug_losses_primal.append(primal_loss.detach().cpu().numpy())\n",
    "\t\taug_losses_fixed_point.append(fixed_point_loss.detach().cpu().numpy())\n",
    "\t\taug_losses_res.append(res_loss.detach().cpu().numpy())\n",
    "\t\taug_losses_steer.append(steer_loss.detach().cpu().numpy())\n",
    "\n",
    "\t\t\n",
    "\t# scale = scale*1.2\t\n",
    "\t\t\n",
    "\tif epoch % 4 == 0:    \n",
    "\t\tprint(f\"Epoch: {epoch + 1}, Train Loss: {np.average(losses_train):.3f}, aug_loss_primal: {np.average(aug_losses_primal):.3f}, aug_loss_fixed_point: {np.average(aug_losses_fixed_point):.3f}, res_loss: {np.average(aug_losses_res):.3f}, steer_loss: {np.average(aug_losses_steer):.3f} \")\n",
    "\n",
    "\tstep += 0.15 #0.15\n",
    "\tscheduler.step()\n",
    "\tavg_train_loss.append(np.average(losses_train)), avg_loss_primal.append(np.average(aug_losses_primal)), avg_fixed_point_loss.append(np.average(aug_losses_fixed_point)),  avg_res_loss.append(np.average(aug_losses_res)), avg_steer_loss.append(np.average(aug_losses_steer))\n",
    "\t\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './weights/learned_qcqp_model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
